<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="renderer" content="webkit">
        <title>vstar</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="nextqa">
        <link href="./resources/bootstrap.min.css" rel="stylesheet">
        <link href="./resources/common.css" rel="stylesheet">
    </head>

    <body data-spy="scroll" data-target=".navbar" data-new-gr-c-s-check-loaded="14.991.0" data-gr-ext-installed="">
		<div style="max-width: 900px;margin:auto;">
            <section id="introduction" class="scrollable-section">
                <div class="content-container">
                    <h3 align="center">VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions</h3>
					<table align="center" width="600px">
					<tbody><tr>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:18px"><a href="#">Yuxuan Wang</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:18px"><a href="#">Zilong Zheng</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align="center" width="100px">
	  					<center>
	  						<span style="font-size:18px"><a href="#">Xueliang Zhao</a></span>
		  		  		</center>
		  		  	  </td>
                    </tr>
					<td align="center" width="100px">
						<center>
							<span style="font-size:18px"><a href="#">Jinpeng Li</a></span>
						</center>
					</td>
                    <td align="center" width="100px">
						<center>
							<span style="font-size:18px"><a href="#">Yueqian Wang</a></span>
						</center>
					</td>
                    <td align="center" width="100px">
						<center>
							<span style="font-size:18px"><a href="#">Dongyan Zhao</a></span>
						</center>
					</td>
				</tr>
				</tbody></table>
				<a href="https://arxiv.org/pdf/2305.18756.pdf">
				<img src="resources/images/vstar_paper.jpg" style="width:100%;border: 0px solid #AAA;">
				</a>
			<iframe width="750" height="470" style="display:block; margin-left: auto; margin-right: auto;"
				src="https://www.youtube.com/embed/ZTZNKy4tXV4">
				</iframe>
                </div>
            </section>
        <div style="max-width: 900px;margin:auto;">
            <section id="introduction" class="scrollable-section">
                <div class="content-container">
                    <h3>Introduction</h3>
					<p>
                        Video-grounded dialogue understanding is a challenging problem that requires machine to perceive, parse and reason over situated semantics extracted from weakly aligned video and dialogues. 
                        Most existing benchmarks treat both modalities the same as a frame-independent visual understanding task, while neglecting the intrinsic attributes in multimodal dialogues, such as scene and topic transitions.   
                        In this work, we present Video-grounded Scene&Topic AwaRe dialogue (VSTAR) dataset, a large scale video-grounded dialogue understanding dataset based on 395 TV series. 
                        Based on VSTAR, we propose two benchmarks for video-grounded dialogue understanding: scene segmentation and topic segmentation, and one benchmark for video-grounded dialogue generation.
                    </p>
					<center>
					  <a><img class="rounded" src="./resources/images/intro.jpg" width="900px"></a><br>
				</center>
                </div>
            </section>
            <section id="statistics" class="scrollable-section">
                <div class="content-container">
                <h3>Data Statistics</h3>
                        <strong>VSTAR</strong> contains a total of 8159 TV episodes and corresponding meta data (genres, keywords, story lines). We specially annotate for each video about dialogue scene and topic transitions. The dataset are split into train/val/test: 172,041/9,573/9,779 ~90 seconds video clips, in which
                        the 9,779 test video clips are held out for futher study. 
                </div>
            
                    <div class="row">
                        <!-- <div style="height:500px;" class="col-md-6 col-xs-12" id="sunburst"></div> -->
                        <!-- <div style="height:500px;" class="col-md-6 col-xs-12">
                            <div style="width:100%;height:250px;" id="histogram"></div>
                            <div style="width:100%;height:250px;" id="bar"></div>
                        </div> -->
                        <div style="" class="col-md-12 col-xs-12" id="table">
                            <div class="col-md-5 col-xs-12 title" style="padding:0">
                                <div style="" class="section">
                                    <div style="height:46px;width:100%">
                                        <div class="col-md-12 col-xs-12 text" >Video clips</div>
                                    </div>
                                    <div style="height:2px;margin:0 4%;background: black"></div>
                                    <div style="height:18px;width:100%">
                                        <div class="col-md-3 col-xs-3 text" >Train</div>
                                        <div class="col-md-3 col-xs-3 text" >Val</div>
                                        <div class="col-md-3 col-xs-3 text" >Test</div>
                                        <div class="col-md-3 col-xs-3 text" >Total</div>
                                    </div>
                                </div>
                                <div style="" class="section">
                                    <div class="col-md-3 col-xs-3 data" style="line-height:100px">172,041</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:100px">9,753</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:100px">9,779</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:100px">191,573</div>
                                </div>
                            </div>
                            <div class="col-md-2 col-xs-12 title" style="padding:0">
                                <div style="line-height: 100px" class="section">
                                    Annotations
                                </div>
                                <div style="font-size:16px;font-weight: 600;line-height: 45px" class="section">
                                    Scene<br/>
                                    Topic
                                </div>
                            </div>
                            <div class="col-md-5 col-xs-12 title" style="padding:0">
                                <div style="" class="section">
                                    <div style="height:46px;width:100%">
                                        <div class="col-md-12 col-xs-12 text" >Segments</div>
                                    </div>
                                    <div style="height:2px;margin:0 4%;background: black"></div>
                                    <div style="height:18px;width:100%">
                                        <div class="col-md-3 col-xs-3 text" >Train</div>
                                        <div class="col-md-3 col-xs-3 text" >Val</div>
                                        <div class="col-md-3 col-xs-3 text" >Test</div>
                                        <div class="col-md-3 col-xs-3 text" >Total</div>
                                    </div>
                                </div>
                                <div style="" class="section">
                                    <div class="col-md-3 col-xs-3 data" style="line-height:45px">417,154<br/>633,649</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:45px">25,777<br/>41,834</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:45px">26,165<br/>42,010</div>
                                    <div class="col-md-3 col-xs-3 data" style="line-height:45px">469,096<br/>717,493</div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
			<section id="introduction" class="scrollable-section">
                <div class="content-container">
                    <h3>Examples</h3>
					
					Case study for scene segmentation of the base model. The green bars indicate correct segmentations, the red bars indicate wrong (false-positive) ones, and the yellow bars indicate missed (true-negative) ones. 
                    In addition, the grey bars indicate correct topic segmentation.
				
					<center>
					  <a><img class="rounded" src="./resources/images/example.png" width="900px"></a><br>
				</center>
                </div>
            </section>
			<section id="download" class="scrollable-section">
                <div class="content-container">
                <h3>Download</h3>
                    <p>
					<li> <a href='https://pan.baidu.com/s/1eBWreYWDDFQd1cj19QxdRg?pwd=xszm', target='_Blank'>Precomputed video features</a> (we are polishing an agreement for additional access to the original video) </li>
					<li> <a href='https://pan.baidu.com/s/1sV1rLadxNnhQbAsr_r75Ow?pwd=b2m9', target='_blank'>Dialogues and Annotations (BaiduNetDisk)</a>, <a href='https://drive.google.com/drive/folders/16vB8bqDtkrYPGKBV_Og3Fk77yDrUi187?usp=sharing', target='_blank'>Gdrive</a></li>
                       Interested in VSTAR and want to try it? Please refer to our <a href="https://github.com/patrick-tssn/VSTAR">Github</a> page on how to use the dataset.
                    Any questions please feel free to contact Yuxuan Wang (<a href="mailto:flagwyx@gmail.com">flagwyx@gmail.com</a>).
					</p>
                </div>
            </section>
					
            <section id="citation" class="scrollable-section">
                <div class="content-container">
				<h3>Citation</h3>
				  <pre style="font-size:12px;">
@inproceedings{wang-etal-2023-vstar,
    title = "{VSTAR}: A Video-grounded Dialogue Dataset for Situated Semantic Understanding with Scene and Topic Transitions",
    author = "Wang, Yuxuan  and
        Zheng, Zilong  and
        Zhao, Xueliang  and
        Li, Jinpeng  and
        Wang, Yueqian  and
        Zhao, Dongyan",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.276",
    pages = "5036--5048",
    abstract = "Video-grounded dialogue understanding is a challenging problem that requires machine to perceive, parse and reason over situated semantics extracted from weakly aligned video and dialogues. Most existing benchmarks treat both modalities the same as a frame-independent visual understanding task, while neglecting the intrinsic attributes in multimodal dialogues, such as scene and topic transitions. In this paper, we present \textbf{Video-grounded Scene{\&}Topic AwaRe dialogue (VSTAR)} dataset, a large scale video-grounded dialogue understanding dataset based on 395 TV series. Based on VSTAR, we propose two benchmarks for video-grounded dialogue understanding: scene segmentation and topic segmentation, and one benchmark for video-grounded dialogue generation. Comprehensive experiments are performed on these benchmarks to demonstrate the importance of multimodal information and segments in video-grounded dialogue understanding and generation.",
}
                    
				  </pre>
                </div>
            </section>
			
            <section id="acknowledge" class="scrollable-section">
                <div class="content-container">
                <!-- <h3>Acknowledgement</h3>
                    <p>
                        We appreciate the help from 
                    </p>
                </div> -->
            </section>
        </div>
        <footer class="footer" style="padding-top: 50px;">
            <div class="container">
                <hr>
                <p style="font-style: italic; text-align: center">
                    Copyright ©  <a class="black" href="https://www.wict.pku.edu.cn/">WICT</a>/
                    <a class="black" href="https://www.bigai.ai/">BIGAI</a>
                </p>
            </div>
        </footer>

        <script type="text/javascript" src="resources/jquery-3.2.1.min.js"></script>
        <script type="text/javascript" src="resources/bootstrap.min.js"></script>
        <script type="text/javascript" src="resources/jquery.easing.min.js"></script>
        <script type="text/javascript" src="resources/scrolling-nav.js"></script>
        <script type="text/javascript" src="resources/echarts/echarts.min.js"></script>
        <script type="text/javascript" src="resources/echarts/echarts-gl.min.js"></script>
        <script type="text/javascript" src="resources/echarts/ecStat.min.js"></script>
        <script type="text/javascript" src="resources/echarts/extension/dataTool.min.js"></script>
        <script type="text/javascript" src="resources/sunburst.js"></script>

</body></html>
